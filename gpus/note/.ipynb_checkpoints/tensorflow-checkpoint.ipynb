{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "#import tensorflow.keras as keras\n",
    "\n",
    "#from tensorflow.python.client import device_lib \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_csv = 'iris_training.csv'\n",
    "testing_csv = 'iris_test.csv'\n",
    "full_set_csv = 'iris_data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NVIDIA® GPU drivers —CUDA 9.0 requires 384.x or higher. \\\n",
    "CUDA® Toolkit —TensorFlow supports CUDA 9.0. \\\n",
    "CUPTI ships with the CUDA Toolkit. ]\n",
    "cuDNN SDK (>= 7.2) Note: Make sure your GPU has compute compatibility >3.0 \\\n",
    "(Optional) NCCL 2.2 for multiple GPU support. \\\n",
    "(Optional) TensorRT 4.0 to improve latency and throughput for inference on some models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputs should all end up in the log\n",
    "# (maybe also save/compress models used for manual/later inspection?)\n",
    "\n",
    "#import logging\n",
    "#\n",
    "#logname = '../output/tf-cuda.log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:00.0 VGA compatible controller: NVIDIA Corporation GM204 [GeForce GTX 980] (rev a1)\r\n",
      "01:00.1 Audio device: NVIDIA Corporation GM204 High Definition Audio Controller (rev a1)\r\n"
     ]
    }
   ],
   "source": [
    "! lspci | grep -i nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:00.0 VGA compatible controller: NVIDIA Corporation GM204 [GeForce GTX 980] (rev a1) (prog-if 00 [VGA controller])\r\n",
      "\tSubsystem: eVga.com. Corp. GM204 [GeForce GTX 980]\r\n",
      "\tPhysical Slot: 3\r\n",
      "\tFlags: bus master, fast devsel, latency 0, IRQ 44, NUMA node 0\r\n",
      "\tMemory at c5000000 (32-bit, non-prefetchable) [size=16M]\r\n",
      "\tMemory at b0000000 (64-bit, prefetchable) [size=256M]\r\n",
      "\tMemory at c0000000 (64-bit, prefetchable) [size=32M]\r\n",
      "\tI/O ports at 6000 [size=128]\r\n",
      "\tExpansion ROM at 000c0000 [disabled] [size=128K]\r\n",
      "\tCapabilities: <access denied>\r\n",
      "\tKernel driver in use: nouveau\r\n",
      "\tKernel modules: nvidiafb, nouveau, nvidia_drm, nvidia\r\n",
      "\r\n",
      "07:00.0 VGA compatible controller: ASPEED Technology, Inc. ASPEED Graphics Family (rev 30) (prog-if 00 [VGA controller])\r\n",
      "\tSubsystem: ASUSTeK Computer Inc. ASPEED Graphics Family\r\n",
      "\tFlags: medium devsel, IRQ 16, NUMA node 0\r\n",
      "\tMemory at c2000000 (32-bit, non-prefetchable) [size=32M]\r\n",
      "\tMemory at c4000000 (32-bit, non-prefetchable) [size=128K]\r\n",
      "\tI/O ports at 3000 [size=128]\r\n",
      "\tCapabilities: <access denied>\r\n",
      "\tKernel driver in use: ast\r\n",
      "\tKernel modules: ast\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! lspci | grep ' VGA ' | cut -d\" \" -f 1 | xargs -i lspci -v -s {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard               2.7.0                    pypi_0    pypi\r\n",
      "tensorboard-data-server   0.6.1                    pypi_0    pypi\r\n",
      "tensorboard-plugin-wit    1.8.0                    pypi_0    pypi\r\n",
      "tensorflow                2.7.0                    pypi_0    pypi\r\n",
      "tensorflow-base           2.2.0           gpu_py37h8a81be8_0  \r\n",
      "tensorflow-estimator      2.7.0                    pypi_0    pypi\r\n",
      "tensorflow-gpu            2.2.0                h0d30ee6_0  \r\n",
      "tensorflow-io-gcs-filesystem 0.22.0                   pypi_0    pypi\r\n"
     ]
    }
   ],
   "source": [
    "! conda list | fgrep -i -e tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cudatoolkit               10.1.243             h6bb024c_0  \r\n",
      "cudnn                     7.6.5                cuda10.1_0  \r\n"
     ]
    }
   ],
   "source": [
    "! conda list | fgrep -i -e cud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: nvidia-smi: not found\r\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/nvcc\n",
      "\tlibicudata.so.66 (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libicudata.so.66\n",
      "\tlibicudata.so (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libicudata.so\n",
      "\tlibcudart.so.10.1 (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libcudart.so.10.1\n",
      "\tlibcudart.so (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libcudart.so\n",
      "\tlibcuda.so.1 (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libcuda.so.1\n",
      "\tlibcuda.so (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libcuda.so\n"
     ]
    }
   ],
   "source": [
    "! which nvcc\n",
    "! ldconfig -p | grep cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking what tensorflow sees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! conda create --name tf_gpu_test tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! conda activate tf_gpu_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-589d4b0a2912>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_physical_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "len(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.is_gpu_available(\n",
    "  cuda_only=False, min_cuda_compute_capability=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 18113468798814556191\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 15272259376501104682\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "CommandNotFoundError: Your shell has not been properly configured to use 'conda deactivate'.\r\n",
      "To initialize your shell, run\r\n",
      "\r\n",
      "    $ conda init <SHELL_NAME>\r\n",
      "\r\n",
      "Currently supported shells are:\r\n",
      "  - bash\r\n",
      "  - fish\r\n",
      "  - tcsh\r\n",
      "  - xonsh\r\n",
      "  - zsh\r\n",
      "  - powershell\r\n",
      "\r\n",
      "See 'conda init --help' for more information and options.\r\n",
      "\r\n",
      "IMPORTANT: You may need to close and restart your shell after running 'conda init'.\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "#! conda deactivate tf_gpu_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo with iris data\n",
    "Code sampled from: https://rubikscode.net/2021/08/03/introduction-to-tensorflow-with-python-example/ \\\n",
    "Dataset from: https://archive.ics.uci.edu/ml/datasets/iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_NAMES = [\n",
    "        'SepalLength', \n",
    "        'SepalWidth',\n",
    "        'PetalLength', \n",
    "        'PetalWidth', \n",
    "        'Species'\n",
    "        ]\n",
    "\n",
    "columns_feat = [\n",
    "    tf.feature_column.numeric_column(key='SepalLength'),\n",
    "    tf.feature_column.numeric_column(key='SepalWidth'),\n",
    "    tf.feature_column.numeric_column(key='PetalLength'),\n",
    "    tf.feature_column.numeric_column(key='PetalWidth')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv( training_csv , names=COLUMN_NAMES, header=0)\n",
    "\n",
    "test_dataset = pd.read_csv(testing_csv, names=COLUMN_NAMES, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_dataset.iloc[:, 0:4]\n",
    "train_y = train_dataset.iloc[:, 4]\n",
    "\n",
    "test_x = test_dataset.iloc[:, 0:4]\n",
    "test_y = test_dataset.iloc[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_function( inputs, outputs, batch_size ):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(( dict(inputs), outputs ))\n",
    "    dataset = dataset.shuffle( 1000 ).repeat().batch( batch_size )\n",
    "    \n",
    "    return dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "def evaluation_function( attributes, classes, batch_size ):\n",
    "    attributes = dict( attributes )\n",
    "    \n",
    "    if classes is None:\n",
    "        inputs = attributes\n",
    "    else:\n",
    "        inputs = (attributes, classes)\n",
    "        \n",
    "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "    \n",
    "    assert batch_size is not None, \"batch_size must not be None\"\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    return dataset.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns = columns_feat,\n",
    "    hidden_units = [10, 10],\n",
    "    n_classes = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.train(\n",
    "    input_fn = lambda : train_function( train_x, train_y, 100 ),\n",
    "    steps = 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result = classifier.evaluate(\n",
    "    input_fn = lambda : evaluation_function( test_x, test_y, 100 )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv( full_set_csv, names = COLUMN_NAMES, header = 0 )\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Species'] = data['Species'].astype(\"category\")\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMatt = data[ COLUMN_NAMES ].corr()\n",
    "\n",
    "mask = np.array( corrMatt )\n",
    "mask[ np.tril_indices_from( mask ) ] = False\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "fig.set_size_inches(20,10)\n",
    "\n",
    "sn.heatmap( corrMatt, mask = mask, vmax = .8, square = True, annot = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = data[\"Species\"]\n",
    "input_data = data.drop( \"Species\", axis = 1 )\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( input_data, output_data, test_size=0.3, random_state=72 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisClassifier( Model ):\n",
    "    def __init__( self ):\n",
    "        super( IrisClassifier, self ).__init__()\n",
    "        \n",
    "        self.layer1 = Dense(10, activation='relu')\n",
    "        self.layer2 = Dense(10, activation='relu')\n",
    "        self.outputLayer = Dense(3, activation='softmax')\n",
    "\n",
    "    def call( self, x ):\n",
    "        x = self.layer1( x )\n",
    "        x = self.layer2( x )\n",
    "        \n",
    "        return self.outputLayer( x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IrisClassifier()\n",
    "\n",
    "model.compile( optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit( X_train, y_train, epochs = 300, batch_size = 10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"\\nAccuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict( X_test )\n",
    "prediction1 = pd.DataFrame({'IRIS1':prediction[:,0],'IRIS2':prediction[:,1], 'IRIS3':prediction[:,2]})\n",
    "prediction1.round( decimals = 4 ).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
