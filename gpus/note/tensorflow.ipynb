{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import tensorflow.keras as keras\n",
    "\n",
    "from tensorflow.python.client import device_lib \n",
    "\n",
    "#import pandas as pd\n",
    "\n",
    "# import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_csv = 'iris_training.csv'\n",
    "testing_csv = 'iris_test.csv'\n",
    "full_set_csv = 'iris_data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NVIDIA® GPU drivers —CUDA 9.0 requires 384.x or higher. \\\n",
    "CUDA® Toolkit —TensorFlow supports CUDA 9.0. \\\n",
    "CUPTI ships with the CUDA Toolkit. ]\n",
    "cuDNN SDK (>= 7.2) Note: Make sure your GPU has compute compatibility >3.0 \\\n",
    "(Optional) NCCL 2.2 for multiple GPU support. \\\n",
    "(Optional) TensorRT 4.0 to improve latency and throughput for inference on some models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputs should all end up in the log\n",
    "# (maybe also save/compress models used for manual/later inspection?)\n",
    "\n",
    "#import logging\n",
    "#\n",
    "#logname = '../output/tf-cuda.log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:00.0 VGA compatible controller: NVIDIA Corporation GM204 [GeForce GTX 980] (rev a1)\r\n",
      "01:00.1 Audio device: NVIDIA Corporation GM204 High Definition Audio Controller (rev a1)\r\n"
     ]
    }
   ],
   "source": [
    "! lspci | grep -i nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:00.0 VGA compatible controller: NVIDIA Corporation GM204 [GeForce GTX 980] (rev a1) (prog-if 00 [VGA controller])\r\n",
      "\tSubsystem: eVga.com. Corp. GM204 [GeForce GTX 980]\r\n",
      "\tPhysical Slot: 3\r\n",
      "\tFlags: bus master, fast devsel, latency 0, IRQ 44, NUMA node 0\r\n",
      "\tMemory at c5000000 (32-bit, non-prefetchable) [size=16M]\r\n",
      "\tMemory at b0000000 (64-bit, prefetchable) [size=256M]\r\n",
      "\tMemory at c0000000 (64-bit, prefetchable) [size=32M]\r\n",
      "\tI/O ports at 6000 [size=128]\r\n",
      "\tExpansion ROM at 000c0000 [disabled] [size=128K]\r\n",
      "\tCapabilities: <access denied>\r\n",
      "\tKernel driver in use: nouveau\r\n",
      "\tKernel modules: nvidiafb, nouveau, nvidia_drm, nvidia\r\n",
      "\r\n",
      "07:00.0 VGA compatible controller: ASPEED Technology, Inc. ASPEED Graphics Family (rev 30) (prog-if 00 [VGA controller])\r\n",
      "\tSubsystem: ASUSTeK Computer Inc. ASPEED Graphics Family\r\n",
      "\tFlags: medium devsel, IRQ 16, NUMA node 0\r\n",
      "\tMemory at c2000000 (32-bit, non-prefetchable) [size=32M]\r\n",
      "\tMemory at c4000000 (32-bit, non-prefetchable) [size=128K]\r\n",
      "\tI/O ports at 3000 [size=128]\r\n",
      "\tCapabilities: <access denied>\r\n",
      "\tKernel driver in use: ast\r\n",
      "\tKernel modules: ast\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! lspci | grep ' VGA ' | cut -d\" \" -f 1 | xargs -i lspci -v -s {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    93.782] (II) LoadModule: \"glx\"\r\n",
      "[    93.861] (II) LoadModule: \"nvidia\"\r\n",
      "[    93.873] (II) LoadModule: \"fb\"\r\n",
      "[    93.874] (II) LoadModule: \"wfb\"\r\n",
      "[    93.875] (II) LoadModule: \"ramdac\"\r\n",
      "[    94.875] (II) LoadModule: \"dri2\"\r\n",
      "[    94.909] (II) LoadModule: \"evdev\"\r\n"
     ]
    }
   ],
   "source": [
    "! grep LoadModule /var/log/Xorg.0.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    93.782] (II) LoadModule: \"glx\"\n",
      "[    93.861] (II) LoadModule: \"nvidia\"\n",
      "[    93.873] (II) LoadModule: \"fb\"\n",
      "[    93.874] (II) LoadModule: \"wfb\"\n",
      "[    93.875] (II) LoadModule: \"ramdac\"\n",
      "[    94.875] (II) LoadModule: \"dri2\"\n",
      "[    94.909] (II) LoadModule: \"evdev\"\n",
      "grep: /etc/X11/xorg.conf: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! grep Driver /etc/X11/xorg.conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard               2.8.0                    pypi_0    pypi\r\n",
      "tensorboard-data-server   0.6.1                    pypi_0    pypi\r\n",
      "tensorboard-plugin-wit    1.8.0                    pypi_0    pypi\r\n",
      "tensorflow                2.8.0                    pypi_0    pypi\r\n",
      "tensorflow-base           2.2.0           gpu_py37h8a81be8_0  \r\n",
      "tensorflow-estimator      2.7.0                    pypi_0    pypi\r\n",
      "tensorflow-gpu            2.2.0                h0d30ee6_0  \r\n",
      "tensorflow-io-gcs-filesystem 0.24.0                   pypi_0    pypi\r\n"
     ]
    }
   ],
   "source": [
    "! conda list | fgrep -i -e tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cudatoolkit               10.1.243             h6bb024c_0  \r\n",
      "cudnn                     7.6.5                cuda10.1_0  \r\n"
     ]
    }
   ],
   "source": [
    "! conda list | fgrep -i -e cud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: nvidia-smi: not found\r\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/nvcc\n",
      "\tlibicudata.so.66 (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libicudata.so.66\n",
      "\tlibicudata.so (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libicudata.so\n",
      "\tlibcudart.so.10.1 (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libcudart.so.10.1\n",
      "\tlibcudart.so (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libcudart.so\n",
      "\tlibcuda.so.1 (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libcuda.so.1\n",
      "\tlibcuda.so (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libcuda.so\n"
     ]
    }
   ],
   "source": [
    "! which nvcc\n",
    "! ldconfig -p | grep cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking what tensorflow sees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10642385634769806508\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py',\n",
       " '-f',\n",
       " '/home/bailey/.local/share/jupyter/runtime/kernel-89840218-868b-46a8-9626-255287910b02.json']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "\n",
    "device_name = sys.argv#[1]  # Choose device from cmd line. Options: gpu or cpu\n",
    "device_name\n",
    "#shape = (int(sys.argv[2]), int(sys.argv[2]))\n",
    "#if device_name == \"gpu\":\n",
    "#    device_name = \"/gpu:0\"\n",
    "#else:\n",
    "#    device_name = \"/cpu:0\"\n",
    "#\n",
    "#with tf.device(device_name):\n",
    "#    random_matrix = tf.random_uniform(shape=shape, minval=0, maxval=1)\n",
    "#    dot_operation = tf.matmul(random_matrix, tf.transpose(random_matrix))\n",
    "#    sum_operation = tf.reduce_sum(dot_operation)\n",
    "#\n",
    "#\n",
    "#startTime = datetime.now()\n",
    "#with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as session:\n",
    "#        result = session.run(sum_operation)\n",
    "#        print(result)\n",
    "#\n",
    "## It can be hard to see the results on the terminal with lots of output -- add some newlines to improve readability.\n",
    "#print(\"\\n\" * 5)\n",
    "#print(\"Shape:\", shape, \"Device:\", device_name)\n",
    "#print(\"Time taken:\", datetime.now() - startTime)\n",
    "#\n",
    "#print(\"\\n\" * 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo with iris data\n",
    "Code sampled from: https://rubikscode.net/2021/08/03/introduction-to-tensorflow-with-python-example/ \\\n",
    "Dataset from: https://archive.ics.uci.edu/ml/datasets/iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_NAMES = [\n",
    "        'SepalLength', \n",
    "        'SepalWidth',\n",
    "        'PetalLength', \n",
    "        'PetalWidth', \n",
    "        'Species'\n",
    "        ]\n",
    "\n",
    "columns_feat = [\n",
    "    tf.feature_column.numeric_column(key='SepalLength'),\n",
    "    tf.feature_column.numeric_column(key='SepalWidth'),\n",
    "    tf.feature_column.numeric_column(key='PetalLength'),\n",
    "    tf.feature_column.numeric_column(key='PetalWidth')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv( training_csv , names=COLUMN_NAMES, header=0)\n",
    "\n",
    "test_dataset = pd.read_csv(testing_csv, names=COLUMN_NAMES, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_dataset.iloc[:, 0:4]\n",
    "train_y = train_dataset.iloc[:, 4]\n",
    "\n",
    "test_x = test_dataset.iloc[:, 0:4]\n",
    "test_y = test_dataset.iloc[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_function( inputs, outputs, batch_size ):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(( dict(inputs), outputs ))\n",
    "    dataset = dataset.shuffle( 1000 ).repeat().batch( batch_size )\n",
    "    \n",
    "    return dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "def evaluation_function( attributes, classes, batch_size ):\n",
    "    attributes = dict( attributes )\n",
    "    \n",
    "    if classes is None:\n",
    "        inputs = attributes\n",
    "    else:\n",
    "        inputs = (attributes, classes)\n",
    "        \n",
    "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "    \n",
    "    assert batch_size is not None, \"batch_size must not be None\"\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    return dataset.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns = columns_feat,\n",
    "    hidden_units = [10, 10],\n",
    "    n_classes = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.train(\n",
    "    input_fn = lambda : train_function( train_x, train_y, 100 ),\n",
    "    steps = 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result = classifier.evaluate(\n",
    "    input_fn = lambda : evaluation_function( test_x, test_y, 100 )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv( full_set_csv, names = COLUMN_NAMES, header = 0 )\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Species'] = data['Species'].astype(\"category\")\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMatt = data[ COLUMN_NAMES ].corr()\n",
    "\n",
    "mask = np.array( corrMatt )\n",
    "mask[ np.tril_indices_from( mask ) ] = False\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "fig.set_size_inches(20,10)\n",
    "\n",
    "sn.heatmap( corrMatt, mask = mask, vmax = .8, square = True, annot = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = data[\"Species\"]\n",
    "input_data = data.drop( \"Species\", axis = 1 )\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( input_data, output_data, test_size=0.3, random_state=72 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisClassifier( Model ):\n",
    "    def __init__( self ):\n",
    "        super( IrisClassifier, self ).__init__()\n",
    "        \n",
    "        self.layer1 = Dense(10, activation='relu')\n",
    "        self.layer2 = Dense(10, activation='relu')\n",
    "        self.outputLayer = Dense(3, activation='softmax')\n",
    "\n",
    "    def call( self, x ):\n",
    "        x = self.layer1( x )\n",
    "        x = self.layer2( x )\n",
    "        \n",
    "        return self.outputLayer( x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IrisClassifier()\n",
    "\n",
    "model.compile( optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit( X_train, y_train, epochs = 300, batch_size = 10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"\\nAccuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict( X_test )\n",
    "prediction1 = pd.DataFrame({'IRIS1':prediction[:,0],'IRIS2':prediction[:,1], 'IRIS3':prediction[:,2]})\n",
    "prediction1.round( decimals = 4 ).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
